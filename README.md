# Multi-Agent Tensor XAI Engine

## Описание

Проект представляет собой интерактивную симуляцию двух автономных агентов (роботов), которые используют тензорные модели глубокого обучения с подкреплением (Reinforcement Learning) для навигации в двумерной среде. Реализация построена на TensorFlow.js и включает визуализацию тепловых карт Q-значений в реальном времени — элемент Explainable AI (XAI).

## Основные возможности

- **Два независимых агента** с разными начальными позициями и целями
- **Динамическое обучение с подкреплением** на основе Q-обучения
- **Тензорное представление состояний и действий** с пространственно-исторической моделью
- **Визуализация тепловых карт** Q-значений для действий «Вперёд» и «Поворот»
- **Интерактивное игровое поле** с препятствиями и системой коллизий
- **Автоматическое переключение режимов** («Загрузка» → «Возврат»)

## Как запустить

1. Склонируйте репозиторий:
```bash
git clone <URL репозитория>
```

2. Откройте файл `index.html` в любом современном браузере (Chrome, Firefox, Edge).

3. Симуляция запустится автоматически. Агенты начнут обучение в реальном времени.

## Как это работает

### Среда
- Поле 11×11 клеток
- Каждый робот имеет:
  - Стартовую позицию
  - Целевую точку для загрузки
  - Целевую точку для разгрузки
- Препятствия расположены вертикально в центре

### Агенты
Каждый агент использует собственную нейронную модель с:
- **Пространственными весами** (состояние × действие)
- **Историческим буфером** последних 8 действий
- **Эпсилон-жадной стратегией** (10% случайных действий)

### Действия
- **0**: Движение вперёд в текущем направлении
- **1**: Поворот на 90° по часовой стрелке

### Награды
- `+100` — успешная загрузка/разгрузка
- `+1.2` — успешное движение вперёд
- `-0.1` — стандартный шаг
- `-1.4` — поворот
- `-6.0` — столкновение

## Технические детали

### Архитектура модели
```javascript
class AgentEngine {
    constructor(size, color) {
        this.weights = tf.variable(tf.randomUniform([size, size, 2, this.actions], -0.01, 0.01));
        this.historyBuffer = tf.variable(tf.zeros([8, this.actions]));
        this.historyWeights = tf.variable(tf.fill([8, this.actions], -2.2));
    }
}
```

### Обучение
- **Q-обучение** с коэффициентом дисконтирования γ=0.96
- **Скорость обучения** α=0.3
- **Обновление весов** через scatterND операции

### Визуализация
- Игровое поле отрисовывается на Canvas
- Тепловые карты показывают нормализованные Q-значения для каждого состояния
- Зелёный робот: тепловая карта в зелёных тонах
- Синий робот: тепловая карта в синих тонах

## Интерфейс

![Интерфейс симуляции](https://via.placeholder.com/800x400.png?text=Multi-Agent+XAI+Simulation+Interface)

1. **Игровое поле** (слева):
   - Роботы в виде треугольников
   - Препятствия красного цвета
   - Цели с полупрозрачной заливкой

2. **Панель робота 1** (зелёный):
   - Статус и наличие груза
   - Тепловая карта Q-значений для «Вперёд»
   - Тепловая карта Q-значений для «Поворот»

3. **Панель робота 2** (синий):
   - Аналогичные элементы для второго агента

## Требования

- Современный браузер с поддержкой WebGL
- Доступ к интернету (для загрузки TensorFlow.js)

## Используемые технологии

- **TensorFlow.js** — машинное обучение в браузере
- **HTML5 Canvas** — графика и визуализация
- **ES6+ JavaScript** — объектно-ориентированное программирование

## Возможные улучшения

1. Добавление большего количества агентов
2. Динамическое изменение препятствий
3. Экспорт/импорт обученных моделей
4. Настройка гиперпараметров через интерфейс
5. Визуализация траекторий движения

## Лицензия

MIT License

## Автор

Разработано в рамках исследования по Explainable AI и мультиагентным системам (2026).